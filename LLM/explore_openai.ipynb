{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook is to explore OPENAI API for Prompt Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x1cfffae46d0> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"id\": \"text-search-babbage-doc-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"curie-search-query\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-davinci-003\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1669599635,\n",
       "      \"owned_by\": \"openai-internal\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"dall-e-3\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1698785189,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-babbage-query-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649358449,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage-search-query\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-babbage-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649364043,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-similarity-davinci-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"davinci-similarity\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"curie-similarity\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172510,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage-search-document\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172510,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"dall-e-2\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1698798177,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"curie-instruct-beta\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649364042,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-ada-doc-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-0301\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1677649963,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"davinci-instruct-beta\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649364042,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-16k-0613\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1685474247,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-similarity-babbage-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-davinci-doc-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage-similarity\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-embedding-ada-002\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1671217299,\n",
       "      \"owned_by\": \"openai-internal\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"davinci-search-query\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-similarity-curie-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-instruct\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1692901427,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-16k\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1683758102,\n",
       "      \"owned_by\": \"openai-internal\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-davinci-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649364042,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-davinci-query-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"ada-search-document\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-0613\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1686587434,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"ada-code-search-code\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"davinci-002\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1692634301,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-instruct-0914\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1694122472,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage-002\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1692634615,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"davinci-search-document\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"curie-search-document\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172508,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage-code-search-code\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1677610602,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-ada-query-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"code-search-ada-text-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"babbage-code-search-text\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"code-search-babbage-code-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"ada-search-query\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"ada-code-search-text\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172510,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"tts-1-hd\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1699046015,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-curie-query-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-davinci-002\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649880484,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"code-search-babbage-text-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"ada\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649357491,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-ada-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649364042,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"ada-similarity\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"code-search-ada-code-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172507,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-similarity-ada-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172505,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-davinci-edit-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649809179,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"code-davinci-edit-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649880484,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-search-curie-doc-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1651172509,\n",
       "      \"owned_by\": \"openai-dev\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"gpt-3.5-turbo-1106\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1698959748,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"text-curie-001\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649364043,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"curie\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649359874,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"whisper-1\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1677532384,\n",
       "      \"owned_by\": \"openai-internal\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"tts-1\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1681940951,\n",
       "      \"owned_by\": \"openai-internal\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"davinci\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1649359874,\n",
       "      \"owned_by\": \"openai\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"tts-1-1106\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1699053241,\n",
       "      \"owned_by\": \"system\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": \"tts-1-hd-1106\",\n",
       "      \"object\": \"model\",\n",
       "      \"created\": 1699053533,\n",
       "      \"owned_by\": \"system\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>owned_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-search-babbage-doc-001</td>\n",
       "      <td>model</td>\n",
       "      <td>1651172509</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>curie-search-query</td>\n",
       "      <td>model</td>\n",
       "      <td>1651172509</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>model</td>\n",
       "      <td>1669599635</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dall-e-3</td>\n",
       "      <td>model</td>\n",
       "      <td>1698785189</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text-search-babbage-query-001</td>\n",
       "      <td>model</td>\n",
       "      <td>1651172509</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>whisper-1</td>\n",
       "      <td>model</td>\n",
       "      <td>1677532384</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tts-1</td>\n",
       "      <td>model</td>\n",
       "      <td>1681940951</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>davinci</td>\n",
       "      <td>model</td>\n",
       "      <td>1649359874</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tts-1-1106</td>\n",
       "      <td>model</td>\n",
       "      <td>1699053241</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tts-1-hd-1106</td>\n",
       "      <td>model</td>\n",
       "      <td>1699053533</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id object     created         owned_by\n",
       "0     text-search-babbage-doc-001  model  1651172509       openai-dev\n",
       "1              curie-search-query  model  1651172509       openai-dev\n",
       "2                text-davinci-003  model  1669599635  openai-internal\n",
       "3                        dall-e-3  model  1698785189           system\n",
       "4   text-search-babbage-query-001  model  1651172509       openai-dev\n",
       "..                            ...    ...         ...              ...\n",
       "59                      whisper-1  model  1677532384  openai-internal\n",
       "60                          tts-1  model  1681940951  openai-internal\n",
       "61                        davinci  model  1649359874           openai\n",
       "62                     tts-1-1106  model  1699053241           system\n",
       "63                  tts-1-hd-1106  model  1699053533           system\n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(openai.Model.list()['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Explain gravity.\n",
      "Response: \n",
      "\n",
      "In Isaac Newton's laws of motion, the force of gravity is the force that attracts objects towards the center of the Earth. The force of gravity is always attractive and is given by:\n",
      "\n",
      "F = G * m1 * m2 / r2\n",
      "\n",
      "where F is the force of gravity, G is the universal gravitational constant, m1 and m2 are the masses of the objects, and r is the distance between the centers of the objects.\n",
      "\n",
      "Prompt: Can you humorously explain gravity to me?\n",
      "Response: \n",
      "\n",
      "Gravity is when you trip over something and it falls on you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Explain gravity.\",\n",
    "    \"Can you humorously explain gravity to me?\"\n",
    "]\n",
    "\n",
    "for p in prompts:\n",
    "    response = openai.Completion.create(model=\"text-davinci-002\", prompt=p, max_tokens=150)\n",
    "    print(f\"Prompt: {p}\")\n",
    "    print(f\"Response: {response.choices[0].text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Initialize the API\n",
    "openai.api_key = 'YOUR_API_KEY'\n",
    "\n",
    "# Testing different prompts\n",
    "prompts = [\n",
    "    \"Tell me a joke.\",\n",
    "    \"Provide a scientific joke.\",\n",
    "    \"Explain the concept of relativity in simple terms.\",\n",
    "    \"Explain the concept of relativity as if I were a 10-year-old.\"\n",
    "]\n",
    "\n",
    "for p in prompts:\n",
    "    response = openai.Completion.create(model=\"text-davinci-002\", prompt=p, max_tokens=150)\n",
    "    print(f\"Prompt: {p}\")\n",
    "    print(f\"Response: {response.choices[0].text}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat completion api and completion api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7dDKJKKjV6ZkK6DHhkKScDQkC8MzJ at 0x27f7f493f90> JSON: {\n",
       "  \"id\": \"cmpl-7dDKJKKjV6ZkK6DHhkKScDQkC8MzJ\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689580375,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nThe capital of UAE is Abu Dhabi.\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 7,\n",
       "    \"completion_tokens\": 10,\n",
       "    \"total_tokens\": 17\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Completion api\n",
    "\n",
    "openai.Completion.create(\n",
    "    model = 'text-curie-001',\n",
    "    prompt = \"what is the capital of UAE?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Push Notification for Food deliver app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7dDKTu8783ZJbPla7q9Mmxpi2fCqy at 0x27f034e5db0> JSON: {\n",
       "  \"id\": \"cmpl-7dDKTu8783ZJbPla7q9Mmxpi2fCqy\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689580385,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nLooking to enjoy a hearty pasta dish without leaving the comfort of your own home? Look no further than our online food delivery app! With over 1,000 options to choose from, we have the perfect dish for anyone and everyone. Plus,\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"length\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 19,\n",
       "    \"completion_tokens\": 50,\n",
       "    \"total_tokens\": 69\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Completion api\n",
    "\n",
    "openai.Completion.create(\n",
    "    model = 'text-curie-001',\n",
    "    prompt = \"Act as an AI assistant. Generate a marketing line for pasta for online food delivery app.\",\n",
    "    max_tokens = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Push Notification for Talabat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7dHAWg2aADbIV1ryVieB1fcBIGmfo at 0x27f05d02bd0> JSON: {\n",
       "  \"id\": \"cmpl-7dHAWg2aADbIV1ryVieB1fcBIGmfo\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689595144,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nHey there! What could you be craving today? I suggest trying out Talabat, a delicious drink made with Turkish coffee and creamy milk. It's perfect for satisfying a sweet or caffeine cravings! Thanks for choosing Talabat\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"length\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 15,\n",
       "    \"completion_tokens\": 49,\n",
       "    \"total_tokens\": 64\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    model = 'text-curie-001',\n",
    "    prompt = \"Act as an AI assistant. Satisfy your craving with Talabat.\",\n",
    "    max_tokens = 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7dCKB9a0pkJ80LMgif0b0yHKnNxfF at 0x18b6aa225e0> JSON: {\n",
       "  \"id\": \"cmpl-7dCKB9a0pkJ80LMgif0b0yHKnNxfF\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689576523,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nThe parcel with the parcelid 1234 is currently in the processing queue.\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 22,\n",
       "    \"completion_tokens\": 17,\n",
       "    \"total_tokens\": 39\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    model = 'text-curie-001',\n",
    "    prompt = \"Act as an AI assistant. Tell the status of a parcel for Shipa delivery with parcelid=1234\",\n",
    "    max_tokens = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7dCKSXRd8w0gq7eBBeTMHv1OScPmf at 0x18b6aa3ce00> JSON: {\n",
       "  \"id\": \"cmpl-7dCKSXRd8w0gq7eBBeTMHv1OScPmf\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689576540,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\n\\n\\n\\n\\nShipa Ecommerce,\\n\\nWe hope you are well. Here is a notification for you about your next big delivery. Your order will be delivered to India in just a few hours. Make sure you are ready for it!\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"length\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 21,\n",
       "    \"completion_tokens\": 50,\n",
       "    \"total_tokens\": 71\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    model = 'text-curie-001',\n",
    "    prompt = \"Act as an AI assistant. Generate a push notification to Shipa Ecommerce app for cross border delivery\",\n",
    "    max_tokens = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Push Notification for Shipa Logistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7dCL8sqNhjCvRwVK0Tg6TOmKfIwZ3 at 0x18b6a9b4680> JSON: {\n",
       "  \"id\": \"cmpl-7dCL8sqNhjCvRwVK0Tg6TOmKfIwZ3\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689576582,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nShipa is always professional and exceeds the customer's expectations with the quality of service. Orders usually arrive much faster than other international courier companies, with the average delivery time being just four days. The combination of the customer's satisfaction and low prices distinguishes Shipa from its competitors.\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 31,\n",
       "    \"completion_tokens\": 57,\n",
       "    \"total_tokens\": 88\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    model = 'text-curie-001',\n",
    "    prompt = \"Act as an AI assistant. Generate a marketing script for Shipa Ecommerce comparing better price and delivery time as compared to competitors like Aramex.\",\n",
    "    max_tokens = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Push Notification for Careem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7dCLOQpiUE0vkIS4pybUSfb0qE913 at 0x18b6aa441d0> JSON: {\n",
       "  \"id\": \"cmpl-7dCLOQpiUE0vkIS4pybUSfb0qE913\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689576598,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nIf you need a ride, now is the time to book one with Careem! We have specially selected cars to ensure you get a safe and comfortable ride. Just enter your destination and we will take care of the rest.\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 13,\n",
       "    \"completion_tokens\": 47,\n",
       "    \"total_tokens\": 60\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    model = 'text-curie-001',\n",
    "    prompt = \"Generate a push notification to Careem app to book ride now\",\n",
    "    max_tokens = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Push Notification for CAFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7dCLoHuw5JcANaxXYvT8hGYPTtjhA at 0x18b6aa4e220> JSON: {\n",
       "  \"id\": \"cmpl-7dCLoHuw5JcANaxXYvT8hGYPTtjhA\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689576624,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nHi CAFU app users, \\n\\nBook fuel filling now!\\n\\n\\n\\nWe would like to remind you that you can book fuel filling now.\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 14,\n",
       "    \"completion_tokens\": 33,\n",
       "    \"total_tokens\": 47\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    model = 'text-curie-001',\n",
    "    prompt = \"Generate a push notification to CAFU app to book fuel filling now\",\n",
    "    max_tokens = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talk about Traffic rule in Dubai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7dCM87QJ0ICuVLJI46JKvAO5VUtOz at 0x18b6aa00e50> JSON: {\n",
       "  \"id\": \"cmpl-7dCM87QJ0ICuVLJI46JKvAO5VUtOz\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689576644,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nThere are numerous traffic rules in Dubai that everyone should be aware of to stay safe while on the roads. The most important rule is to yield to traffic in the right-hand lanes. Also, be aware of all stop signs and red lights and do not drive through yellow lights if you can\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"length\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 14,\n",
       "    \"completion_tokens\": 60,\n",
       "    \"total_tokens\": 74\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    model = 'text-curie-001',\n",
    "    prompt = \"Act as an AI assistant. what are major traffic rule in Dubai?\",\n",
    "    max_tokens = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7dCMQcNoiyi283fudn8nP2jCPBiPQ at 0x18b6aa1d090> JSON: {\n",
       "  \"id\": \"cmpl-7dCMQcNoiyi283fudn8nP2jCPBiPQ\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689576662,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"?\\n\\nMajor traffic rule in Dubai in Arabic include: \\n-Drive slowly and respect other drivers.\\n-Be aware of your surroundings at all times.\\n-Obey all traffic signs and avoid crossing streets without a marked crosswalk.\\n-Be alert for motorcycles, buses, and\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"length\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 15,\n",
       "    \"completion_tokens\": 60,\n",
       "    \"total_tokens\": 75\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    model = 'text-curie-001',\n",
    "    prompt = \"Act as an AI assistant. what are major traffic rule in Dubai in Arabic\",\n",
    "    max_tokens = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7dCOCz8EvVzp4HqKlN6NIpn33zDtm at 0x18b6aa22d60> JSON: {\n",
       "  \"id\": \"cmpl-7dCOCz8EvVzp4HqKlN6NIpn33zDtm\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689576772,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nSaying \\\"lookalike\\\" is incorrect. It should be spelled \\\"lop-oop.\\\"\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 23,\n",
       "    \"completion_tokens\": 22,\n",
       "    \"total_tokens\": 45\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "    model = 'text-curie-001',\n",
    "    prompt = \"Act as an AI assistant.reverse word l-o-l-l-i-p-o-p\",\n",
    "    max_tokens = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from Google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7d1fiBIlazHzSLPzUkM0ZyhHH24Uz\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1689535574,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"I'm sorry, but as a text-based assistant, I'm unable to directly access external files or URLs. Please provide the text or content of the PDF that you would like me to assist with.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 131,\n",
      "    \"completion_tokens\": 40,\n",
      "    \"total_tokens\": 171\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# import openai\n",
    "\n",
    "# openai.api_key = 'your-api-key'\n",
    "\n",
    "def load_and_query_pdf(pdf_url, query):\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f'chatwithpdf.loadPdf:{{\"pdf_url\": \"{pdf_url}\"}}'},\n",
    "            {\"role\": \"user\", \"content\": f'chatwithpdf.queryPdf:{{\"pdf_url\": \"{pdf_url}\", \"query\": \"{query}\"}}'},\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Load and query a PDF\n",
    "response = load_and_query_pdf(\"https://drive.google.com/file/d/1ryHwy-FLfWpVEDEi9SG0hm-BhWVbA9JJ/view?usp=drive_link\", \"Write summary of the file\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tell the status of shipment by ChatGpt API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parcel</th>\n",
       "      <th>ShipmentCountry</th>\n",
       "      <th>ConsigneeCountry</th>\n",
       "      <th>StatusChangeDate</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parcel-1</td>\n",
       "      <td>Canada</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-03-06 18:25:16</td>\n",
       "      <td>Exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parcel-2</td>\n",
       "      <td>USA</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2022-06-13 15:57:52</td>\n",
       "      <td>In Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parcel-3</td>\n",
       "      <td>France</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2016-08-03 14:03:10</td>\n",
       "      <td>Failed Attempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parcel-4</td>\n",
       "      <td>China</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2022-12-18 12:54:04</td>\n",
       "      <td>Exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parcel-5</td>\n",
       "      <td>Canada</td>\n",
       "      <td>UK</td>\n",
       "      <td>2021-12-01 18:30:55</td>\n",
       "      <td>Exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Parcel-6</td>\n",
       "      <td>Russia</td>\n",
       "      <td>USA</td>\n",
       "      <td>2021-07-15 18:29:04</td>\n",
       "      <td>In Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Parcel-7</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-12-20 03:23:02</td>\n",
       "      <td>Delivered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parcel-8</td>\n",
       "      <td>UK</td>\n",
       "      <td>France</td>\n",
       "      <td>2021-01-01 09:15:33</td>\n",
       "      <td>Failed Attempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Parcel-9</td>\n",
       "      <td>UK</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2020-10-31 11:29:56</td>\n",
       "      <td>In Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Parcel-10</td>\n",
       "      <td>India</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2017-12-12 14:05:59</td>\n",
       "      <td>Out for Delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Parcel-11</td>\n",
       "      <td>Canada</td>\n",
       "      <td>China</td>\n",
       "      <td>2021-05-29 07:42:06</td>\n",
       "      <td>Failed Attempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Parcel-12</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2019-12-07 15:34:34</td>\n",
       "      <td>In Transit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Parcel-13</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2022-06-17 21:27:47</td>\n",
       "      <td>Failed Attempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Parcel-14</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2019-07-07 21:25:24</td>\n",
       "      <td>Exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Parcel-15</td>\n",
       "      <td>UK</td>\n",
       "      <td>India</td>\n",
       "      <td>2015-03-10 17:01:15</td>\n",
       "      <td>Delivered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Parcel-16</td>\n",
       "      <td>Australia</td>\n",
       "      <td>China</td>\n",
       "      <td>2015-10-08 07:05:17</td>\n",
       "      <td>Exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Parcel-17</td>\n",
       "      <td>Australia</td>\n",
       "      <td>China</td>\n",
       "      <td>2021-02-20 22:27:27</td>\n",
       "      <td>Failed Attempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Parcel-18</td>\n",
       "      <td>China</td>\n",
       "      <td>India</td>\n",
       "      <td>2016-01-29 04:14:32</td>\n",
       "      <td>Out for Delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Parcel-19</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2015-02-20 04:32:31</td>\n",
       "      <td>Delivered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Parcel-20</td>\n",
       "      <td>China</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2017-10-28 13:23:40</td>\n",
       "      <td>Exception</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Parcel ShipmentCountry ConsigneeCountry    StatusChangeDate  \\\n",
       "0    Parcel-1          Canada               UK 2020-03-06 18:25:16   \n",
       "1    Parcel-2             USA          Germany 2022-06-13 15:57:52   \n",
       "2    Parcel-3          France           Brazil 2016-08-03 14:03:10   \n",
       "3    Parcel-4           China        Australia 2022-12-18 12:54:04   \n",
       "4    Parcel-5          Canada               UK 2021-12-01 18:30:55   \n",
       "5    Parcel-6          Russia              USA 2021-07-15 18:29:04   \n",
       "6    Parcel-7          Brazil          Germany 2020-12-20 03:23:02   \n",
       "7    Parcel-8              UK           France 2021-01-01 09:15:33   \n",
       "8    Parcel-9              UK           Canada 2020-10-31 11:29:56   \n",
       "9   Parcel-10           India          Germany 2017-12-12 14:05:59   \n",
       "10  Parcel-11          Canada            China 2021-05-29 07:42:06   \n",
       "11  Parcel-12          Brazil           Canada 2019-12-07 15:34:34   \n",
       "12  Parcel-13          Canada           Brazil 2022-06-17 21:27:47   \n",
       "13  Parcel-14          Brazil          Germany 2019-07-07 21:25:24   \n",
       "14  Parcel-15              UK            India 2015-03-10 17:01:15   \n",
       "15  Parcel-16       Australia            China 2015-10-08 07:05:17   \n",
       "16  Parcel-17       Australia            China 2021-02-20 22:27:27   \n",
       "17  Parcel-18           China            India 2016-01-29 04:14:32   \n",
       "18  Parcel-19          Russia           Canada 2015-02-20 04:32:31   \n",
       "19  Parcel-20           China           Brazil 2017-10-28 13:23:40   \n",
       "\n",
       "              Status  \n",
       "0          Exception  \n",
       "1         In Transit  \n",
       "2     Failed Attempt  \n",
       "3          Exception  \n",
       "4          Exception  \n",
       "5         In Transit  \n",
       "6          Delivered  \n",
       "7     Failed Attempt  \n",
       "8         In Transit  \n",
       "9   Out for Delivery  \n",
       "10    Failed Attempt  \n",
       "11        In Transit  \n",
       "12    Failed Attempt  \n",
       "13         Exception  \n",
       "14         Delivered  \n",
       "15         Exception  \n",
       "16    Failed Attempt  \n",
       "17  Out for Delivery  \n",
       "18         Delivered  \n",
       "19         Exception  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randint\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize a Faker object\n",
    "fake = Faker()\n",
    "\n",
    "# Define a function to generate a random date\n",
    "def random_dates(start, end, n=10):\n",
    "    start_u = start.value//10**9\n",
    "    end_u = end.value//10**9\n",
    "    return pd.to_datetime(np.random.randint(start_u, end_u, n), unit='s')\n",
    "\n",
    "# Define the start and end dates\n",
    "start = pd.to_datetime('2015-01-01')\n",
    "end = pd.to_datetime('2022-12-31')\n",
    "\n",
    "# Define the list of countries\n",
    "countries = [\"USA\", \"Canada\", \"UK\", \"Germany\", \"France\", \"Australia\", \"India\", \"China\", \"Russia\", \"Brazil\"]\n",
    "\n",
    "# Define the list of status\n",
    "status = [\"Delivered\", \"In Transit\", \"Out for Delivery\", \"Failed Attempt\", \"Exception\"]\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Parcel\": [f\"Parcel-{i}\" for i in range(1, 21)],\n",
    "    \"ShipmentCountry\": random.choices(countries, k=20),\n",
    "    \"ConsigneeCountry\": random.choices(countries, k=20),\n",
    "    \"StatusChangeDate\": random_dates(start, end, 20),\n",
    "    \"Status\": random.choices(status, k=20)\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello, I need help on my parcel status\n",
      "AI assistant: Please provide your parcel ID.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI assistant: The parcel with ID Parcel-19 was shipped from Russia to Canada. The status was last updated on 2015-02-20 and the current status is Delivered.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "class ParcelChatBot:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        self.parcel_id = None\n",
    "\n",
    "    def get_parcel_info(self, parcel_id):\n",
    "        # Filter the DataFrame to get the record for the specified parcel\n",
    "        parcel_record = self.dataframe[self.dataframe[\"Parcel\"] == parcel_id].iloc[0]\n",
    "\n",
    "        # Prepare the data for the API call\n",
    "        shipment_country = parcel_record[\"ShipmentCountry\"]\n",
    "        consignee_country = parcel_record[\"ConsigneeCountry\"]\n",
    "        status_change_date = parcel_record[\"StatusChangeDate\"].strftime(\"%Y-%m-%d\")\n",
    "        status = parcel_record[\"Status\"]\n",
    "\n",
    "        # Prepare the message for the API call\n",
    "        message = f\"The parcel with ID {parcel_id} was shipped from {shipment_country} to {consignee_country}. The status was last updated on {status_change_date} and the current status is {status}.\"\n",
    "\n",
    "        return message\n",
    "\n",
    "    def process_message(self, message):\n",
    "        if \"parcel status\" in message:\n",
    "            return \"Please provide your parcel ID.\"\n",
    "        elif \"Parcel-\" in message:\n",
    "            self.parcel_id = message.split()[-1]\n",
    "            parcel_info = self.get_parcel_info(self.parcel_id)\n",
    "            return parcel_info\n",
    "        else:\n",
    "            return \"I'm sorry, I didn't understand that. Could you please provide your parcel ID?\"\n",
    "\n",
    "    def chat(self):\n",
    "        print(\"User: Hello, I need help on my parcel status\")\n",
    "        print(\"AI assistant:\", self.process_message(\"Hello, I need help on my parcel status\"))\n",
    "\n",
    "        user_message = input(\"User: \")\n",
    "        print(\"AI assistant:\", self.process_message(user_message))\n",
    "\n",
    "# Replace 'df' with your actual DataFrame\n",
    "chatbot = ParcelChatBot(df)\n",
    "chatbot.chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Product description from Datasheet of different parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The part number is SCCV60E107SRBQ. This is an automotive-grade cylindrical supercapacitor from the SCC series. It has a diameter of 18mm and a length of 60mm. The rated capacitance is 100F with a tolerance of +30%/-10%. It has a rated voltage of 3.0V and can operate in temperatures ranging from -40°C to +65°C. The maximum peak current is 2904A and the power density is 53.57 W/kg. The energy density is 6.05 Wh/kg.\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import openai\n",
    "\n",
    "# Open the PDF file\n",
    "pdf = PdfReader('C:\\\\Users\\\\tariq\\\\Downloads\\\\datasheet\\\\SCCV60E107SRBQ-3084123.pdf')\n",
    "\n",
    "# Initialize an empty string to hold the PDF text\n",
    "pdf_text = ''\n",
    "\n",
    "# Loop through each page in the PDF and add its text to the string\n",
    "for page in pdf.pages:\n",
    "    pdf_text += page.extract_text()\n",
    "\n",
    "\n",
    "# Use the PDF text string as input to the OpenAI API\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is some data: {pdf_text}. tell me the part number and product description?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Crypto.Cipher import AES\n",
    "def process_pdf(file_path):\n",
    "    # Open the PDF file\n",
    "    pdf = PdfReader(file_path)\n",
    "\n",
    "    # Initialize an empty string to hold the PDF text\n",
    "    pdf_text = ''\n",
    "\n",
    "    # Loop through each page in the PDF and add its text to the string\n",
    "    for page in pdf.pages:\n",
    "        pdf_text += page.extract_text()\n",
    "\n",
    "    # Truncate or otherwise reduce the length of the PDF text\n",
    "    max_length = 4096 - 500  # Reserve some tokens for the other messages\n",
    "    if len(pdf_text) > max_length:\n",
    "        pdf_text = pdf_text[:max_length]\n",
    "        \n",
    "    # Use the PDF text string as input to the OpenAI API\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Here is some data: {pdf_text}. tell me the part number and product description?\"},\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\tariq\\Downloads\\datasheet\\202pmlst.pdf\n",
      "The part number for this product is 202 PML-ST. \n",
      "The product description is as follows: Aluminum Electrolytic Capacitors, Power High Ripple Current, Screw Terminals. \n",
      "This product is manufactured by Vishay BCcomponents.\n",
      "Processing file: C:\\Users\\tariq\\Downloads\\datasheet\\KEM_A4098_A780-1915524.pdf\n",
      "The part number for the product described in the data is A780. The product description is a surface mount hybrid aluminum polymer capacitor with outstanding electrical performance. It is designed for use in mobile, automotive, and aircraft installations with operation up to +125°C. It features high ripple current, low leakage current, high vibration resistance, self-healing behavior, and is AEC-Q200 and RoHS compliant.\n",
      "Processing file: C:\\Users\\tariq\\Downloads\\datasheet\\SCCV60E107SRBQ-3084123.pdf\n",
      "The part number is SCCV60E107SRBQ. The product description is as follows:\n",
      "\n",
      "Automotive Grade Cylindrical SuperCapacitor\n",
      "Voltage: 3.0V\n",
      "Diameter: 18mm\n",
      "Length: 60mm\n",
      "Rated Capacitance: 100F\n",
      "Capacitance Tolerance: +30%/-10%\n",
      "Rated Temperature: 65/85°C\n",
      "DCL Max @ 72 Hrs: 260µA\n",
      "ESR Max @ 1000 Hz: 15mΩ\n",
      "ESR Max @ DC: 18mΩ\n",
      "Peak Current: 53.57A\n",
      "Power Density: 2904 W/kg\n",
      "Max Energy: 0.1250 Wh\n",
      "Energy Density: 6.05 Wh/kg\n",
      "Lead Format: Radial\n",
      "Package: Bulk\n",
      "Termination: Compatible with hand soldering and wave soldering processes\n",
      "Custom Code: AEC-Q200\n",
      "Operating Temperature: -40°C to +65°C @ 3.0V\n",
      "-40°C to +85°C with appropriate derating\n",
      "RoHS compatible\n",
      "\n",
      "This product is suitable for applications such as eLatch, eCall, motor stabilization, eVideo, power backup, camera flash systems, energy harvesting, GSM/GSR pulse applications, UPS/industrial, wireless alarms, remote metering, scanners, toys, and games.\n",
      "Processing file: C:\\Users\\tariq\\Downloads\\datasheet\\TDK_HVC27_B88269X.pdf\n",
      "The part number is B88269X* and the product description is High-voltage contactor, gas-filled contactor for high-voltage DC switching (HVC27).\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = 'C:\\\\Users\\\\tariq\\\\Downloads\\\\datasheet' \n",
    "\n",
    "# Iterate over all files in the specified folder\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # Process each PDF file\n",
    "        response = process_pdf(file_path)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\tariq\\Downloads\\datasheet\\202pmlst.pdf\n",
      "Processing file: C:\\Users\\tariq\\Downloads\\datasheet\\KEM_A4098_A780-1915524.pdf\n",
      "Processing file: C:\\Users\\tariq\\Downloads\\datasheet\\SCCV60E107SRBQ-3084123.pdf\n",
      "Processing file: C:\\Users\\tariq\\Downloads\\datasheet\\TDK_HVC27_B88269X.pdf\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def process_pdf(file_path):\n",
    "    # Open the PDF file\n",
    "    pdf = PdfReader(file_path)\n",
    "\n",
    "    # Initialize an empty string to hold the PDF text\n",
    "    pdf_text = ''\n",
    "\n",
    "    # Loop through each page in the PDF and add its text to the string\n",
    "    for page in pdf.pages:\n",
    "        pdf_text += page.extract_text()\n",
    "\n",
    "    # Truncate or otherwise reduce the length of the PDF text\n",
    "    max_length = 4096 - 500  # Reserve some tokens for the other messages\n",
    "    if len(pdf_text) > max_length:\n",
    "        pdf_text = pdf_text[:max_length]\n",
    "\n",
    "    # Use the PDF text string as input to the OpenAI API\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Here is some data: {pdf_text}. tell me the part number and product description?\"},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "def store_responses_in_json(responses, output_path):\n",
    "    with open(output_path, \"w\") as file:\n",
    "        json.dump(responses, file)\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = 'C:\\\\Users\\\\tariq\\\\Downloads\\\\datasheet' \n",
    "\n",
    "# Specify the output path\n",
    "output_path = 'C:\\\\Users\\\\tariq\\\\Downloads\\\\datasheet\\\\responses.json'\n",
    "\n",
    "# Initialize an empty dictionary to hold the responses\n",
    "responses = {}\n",
    "\n",
    "# Iterate over all files in the specified folder\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # Process each PDF file\n",
    "        response = process_pdf(file_path)\n",
    "        responses[file] = response\n",
    "\n",
    "# Store the responses in a JSON file\n",
    "store_responses_in_json(responses, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\tariq\\Downloads\\datasheet\\202pmlst.pdf\n",
      "Processing file: C:\\Users\\tariq\\Downloads\\datasheet\\KEM_A4098_A780-1915524.pdf\n",
      "Processing file: C:\\Users\\tariq\\Downloads\\datasheet\\SCCV60E107SRBQ-3084123.pdf\n",
      "Processing file: C:\\Users\\tariq\\Downloads\\datasheet\\TDK_HVC27_B88269X.pdf\n"
     ]
    }
   ],
   "source": [
    "def process_pdf(file_path):\n",
    "    # Open the PDF file\n",
    "    pdf = PdfReader(file_path)\n",
    "\n",
    "    # Initialize an empty string to hold the PDF text\n",
    "    pdf_text = ''\n",
    "\n",
    "    # Loop through each page in the PDF and add its text to the string\n",
    "    for page in pdf.pages:\n",
    "        pdf_text += page.extract_text()\n",
    "\n",
    "    # Truncate or otherwise reduce the length of the PDF text\n",
    "    max_length = 4096 - 500  # Reserve some tokens for the other messages\n",
    "    if len(pdf_text) > max_length:\n",
    "        pdf_text = pdf_text[:max_length]\n",
    "\n",
    "    # Use the PDF text string as input to the OpenAI API\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Here is some data: {pdf_text}. tell me the part number and product description?\"},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    response_text = response.choices[0].message['content']\n",
    "\n",
    "    # Extract part number from the response\n",
    "    part_number = response_text.split(\" \")[4] # change this based on the actual format\n",
    "\n",
    "    return part_number, response_text\n",
    "\n",
    "# Iterate over all files in the specified folder\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # Process each PDF file\n",
    "        part_number, response = process_pdf(file_path)\n",
    "        responses[part_number] = response\n",
    "\n",
    "# Store the responses in a JSON file\n",
    "store_responses_in_json(responses, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
